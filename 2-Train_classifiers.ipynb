{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "# 自定义py文件\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数设定 & 加载必要数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_splits = 5\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "samples = np.array(load_pickle(\"data/v3/processed/samples_feature.pkl\"))\n",
    "random.shuffle(samples)\n",
    "features, labels = zip(*samples)\n",
    "features = np.array(features, dtype='float')\n",
    "labels = np.array(labels, dtype='int')\n",
    "\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt = QuantileTransformer(n_quantiles=80,output_distribution='normal')\n",
    "\n",
    "# 按方差或最终效果剔除某些特征 78 -6 =72\n",
    "remove_features = [0,2,20,24,44,76]\n",
    "features = np.delete(features, remove_features, axis=1)\n",
    "\n",
    "# 这里用QuantileTransformer来进行scaling\n",
    "transformed_features = qt.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据相关性和特征重要性进行特征交叉 16\n",
    "cross_features = np.array([\n",
    "    transformed_features[:,36] * transformed_features[:,10],\n",
    "    transformed_features[:,1] * transformed_features[:,5],\n",
    "    transformed_features[:,4] * transformed_features[:,6],\n",
    "    transformed_features[:,35] * transformed_features[:,32],\n",
    "    transformed_features[:,37] * transformed_features[:,39],\n",
    "    transformed_features[:,3] * transformed_features[:,8],\n",
    "    transformed_features[:,50] * transformed_features[:,52],\n",
    "    transformed_features[:,40] * transformed_features[:,38],\n",
    "    transformed_features[:,40] * transformed_features[:,41],\n",
    "    transformed_features[:,50] * transformed_features[:,53],\n",
    "    transformed_features[:,41] * transformed_features[:,34],\n",
    "    transformed_features[:,7] * transformed_features[:,8],\n",
    "    transformed_features[:,34] * transformed_features[:,37],\n",
    "    transformed_features[:,22] * transformed_features[:,23],\n",
    "    transformed_features[:,3] * transformed_features[:,7],\n",
    "    transformed_features[:,18] * transformed_features[:,10],\n",
    "])\n",
    "\n",
    "# 72 + 16 = 88\n",
    "features = np.hstack([transformed_features, cross_features.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt_filename = \"data/v3/processed/qt.pkl\"\n",
    "dump_pickle(qt_filename, qt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models():\n",
    "    # Randomforest\n",
    "    rf = RandomForestClassifier(n_estimators=1000,\n",
    "                                criterion='entropy',\n",
    "                                max_features = 25,\n",
    "                                bootstrap=True,\n",
    "                                random_state=42,\n",
    "                                warm_start=False,\n",
    "                                class_weight=None,\n",
    "                                n_jobs=-1,\n",
    "                                )\n",
    "    # XGBoost\n",
    "    xgb = XGBClassifier(\n",
    "                         n_estimators = 1000,\n",
    "                         booster = 'gbtree',\n",
    "                         max_depth = 10, \n",
    "                         #objective = 'binary:logistic',\n",
    "                         reg_lambda = 1,\n",
    "                         subsample = 0.5,\n",
    "                         gamma = 0.5,\n",
    "                         colsample_bytree = 0.75,\n",
    "                         min_child_weight = 2,\n",
    "                         learning_rate  = 0.25,\n",
    "                         n_jobs = -1,\n",
    "                         random_state = 42\n",
    "                        )\n",
    "    # lightGBM\n",
    "    lgbm = LGBMClassifier(\n",
    "                      max_depth=5, \n",
    "                      learning_rate=0.1, \n",
    "                      n_estimators=1000, \n",
    "                      objective='binary',\n",
    "                      subsample=0.8,\n",
    "                      n_jobs=-1,\n",
    "                      num_leaves=30,\n",
    "                      colsample_bytree = 0.75,\n",
    "                      random_state = 42\n",
    "                     )\n",
    "    #catboost\n",
    "    cat = CatBoostClassifier(\n",
    "                      iterations=1000,\n",
    "                      learning_rate=0.1,\n",
    "                      max_depth=7,\n",
    "                      verbose=100,\n",
    "                      task_type='CPU',\n",
    "                      eval_metric='AUC',\n",
    "                      random_state=42,\n",
    "                      thread_count=-1,  \n",
    "                    )\n",
    "    \n",
    "    return rf,xgb,lgbm,cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = features.mean()\n",
    "std = features.std()\n",
    "# 简单归一化\n",
    "features = (features - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存mean和std\n",
    "mean_path = \"data/v3/processed/mean.pkl\"\n",
    "std_path = \"data/v3/processed/std.pkl\"\n",
    "dump_pickle(mean_path, mean)\n",
    "dump_pickle(std_path, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分样本  种子固定 5折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_save_path = \"data/v3/processed/models/\"\n",
    "\n",
    "#%%time\n",
    "xSample = features\n",
    "ySample = labels\n",
    "\n",
    "rf_preds_all = []\n",
    "xgb_preds_all = []\n",
    "lgbm_preds_all = []\n",
    "cat_preds_all = []\n",
    "\n",
    "metrics_dict = {\"rf\": {}, \"xgb\": {}, \"lgbm\": {}, \"cat\": {}}\n",
    "for model in metrics_dict.keys():\n",
    "    metrics_dict[model] = {\"AUC\":0.0, \"ACC\":0.0, \"Recall\":0.0, \"F1-score\":0.0, \"Precesion\":0.0}\n",
    "\n",
    "kf = KFold(n_splits = N_splits)\n",
    "num = 0 \n",
    "for train_index, valid_index in kf.split(xSample):\n",
    "    \n",
    "    train_X, train_y = xSample[train_index], ySample[train_index]\n",
    "    valid_X, valid_y = xSample[valid_index], ySample[valid_index]\n",
    "    \n",
    "    \n",
    "    rf,xgb,lgbm,cat = create_models()\n",
    "    \n",
    "    rf.fit(train_X, train_y)\n",
    "    xgb.fit(train_X, train_y)\n",
    "    lgbm.fit(train_X, train_y)\n",
    "    cat.fit(train_X, train_y)\n",
    "    \n",
    "    rf_preds = rf.predict_proba(valid_X)[:,1]\n",
    "    xgb_preds = xgb.predict_proba(valid_X)[:,1]\n",
    "    lgbm_preds = lgbm.predict_proba(valid_X)[:,1]\n",
    "    cat_preds = cat.predict_proba(valid_X)[:,1]\n",
    "    \n",
    "    rf_preds_all.append(rf_preds)\n",
    "    xgb_preds_all.append(xgb_preds)\n",
    "    lgbm_preds_all.append(lgbm_preds)\n",
    "    cat_preds_all.append(cat_preds)\n",
    "    \n",
    "    \n",
    "    rf_pred_labels = (rf_preds >= 0.5) * 1\n",
    "    xgb_pred_labels = (xgb_preds >= 0.5) * 1\n",
    "    lgbm_pred_labels = (lgbm_preds >= 0.5) * 1\n",
    "    cat_pred_labels = (cat_preds >= 0.5) * 1\n",
    "    \n",
    "    for model in metrics_dict.keys():\n",
    "        metrics_dict[model][\"AUC\"] += metrics.roc_auc_score(valid_y, eval(f'{model}_pred_labels')) / N_splits\n",
    "        metrics_dict[model][\"ACC\"] += metrics.accuracy_score(valid_y, eval(f'{model}_pred_labels')) / N_splits\n",
    "        metrics_dict[model][\"Recall\"] += metrics.recall_score(valid_y, eval(f'{model}_pred_labels')) / N_splits\n",
    "        metrics_dict[model][\"F1-score\"] += metrics.f1_score(valid_y, eval(f'{model}_pred_labels')) / N_splits\n",
    "        metrics_dict[model][\"Precesion\"] += metrics.precision_score(valid_y, eval(f'{model}_pred_labels')) / N_splits\n",
    "    \n",
    "    \n",
    "    dump_pickle(model_save_path + f\"model_{num}_rf.dat\", rf)\n",
    "    dump_pickle(model_save_path + f\"model_{num}_xgb.dat\", xgb)\n",
    "    dump_pickle(model_save_path + f\"model_{num}_lgbm.dat\", lgbm)\n",
    "    dump_pickle(model_save_path + f\"model_{num}_cat.dat\", cat)\n",
    "    \n",
    "    del rf,xgb,lgbm,cat\n",
    "    _ = gc.collect()\n",
    "    \n",
    "    num = num + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
